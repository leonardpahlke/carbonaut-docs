{"/docs/":{"data":{"":"\nCarbonaut is project to collect and refine environmental sustainability data from your IT infrastructure and make it available in a common data schema. The project does not implement a scraper to scan your IT infrastructure or measure your virtual machine energy, but integrates over providers which are implemented as plugins to integrate external data sources. The project is a POC and therefore not production ready. If you like to contribute you are very welcome to do so!\n⚠️ Carbonaut is a proof of concept project which may be turned in the future into a proper open source project. Right now this is not the case. Click me to reveal The aim of the project is to collect and integrate data around environmental sustainability and make it accessible to users so that they can make automatic or manual decisions. The project integrates heterogenous data sources over plugins and transforms the data in a simple minimalistic data schema. Carbonaut discovers created IT infrastructure, maintains a minimalistic internal static resource state and chains dynamic changing data together to collect a holistic overview of cloud native sustainability data. Carbonaut is used with other tools and is due to the plugin design platform agnostic. It’s developed for a cloud native usecase. There are several other tools available which are also about cloud native sustainability.\nKepler measures and exposes energy and carbon emission metrics of Kubernetes clusters. Unlike Carbonaut, Kepler employs its measurement tools, which include RAPL, eBPF approximations, and others. It actively discovers new nodes and pods, updating its measurements accordingly. On the other hand, Carbonaut does not directly measure metrics but integrates with projects that deliver these metrics. Carbonaut is not restricted to Kubernetes, offering a more agnostic approach. Carbonaut is capable of integrating IT infrastructure metrics across platforms like GCP, Equinix, and AWS. It can utilize RAPL measurements on one platform while employing different providers on another, and use EnergyMap to obtain energy mix data for all. Note that not all of these plugins have been implemented yet. If the system is entirely based on Kubernetes, Kepler is likely a better choice (especially at the current stage of development of the Carbonaut project). Scaphandre uses various interfaces to collect energy and resource usage data from a computer. Scaphandre is a lightweight binary that offers various ways to export collected data for further use. Carbonaut implements a Scaphandre provider to collect dynamic resource data (energy consumption, CPU frequency, etc.). Carbonaut provides the interface to the cloud native sustainability information, scaphandre provides the interface to the environmental data of one machine. Kube Green is a Kubernetes operator that looks at pod annotations to schedule and de-schedule them at specific times to improve energy utilization in terms of power mix. Kube Green does not measure or collect data, but uses a static approach to change how the cluster manages its resources. Carbonaut collects and integrates data, but does not change the system topology any further. In the future, the idea of Kube Green could be further developed with the data from Carbonaut. ⚠️ The current Carbonaut version is a POC (Proof of Concept). The project is not tested for large scale environments. There are several security and quality checks already in place but no security assessment was made and there are likely vulnerabilities if deployed. The system is not hardened. The data scheme is minimalistic which aligns with the nature of a POC but lacks therefore complexity which is required to cover all aspects of cloud native sustainability. "},"title":"Documentation"},"/docs/components/":{"data":{"":"","#":" Carbonaut's internal components are explained in this document. At a high level, Carbonaut serves metrics and integration functionallity over a server component which calls endpoints in the connector to collect metrics. The connector is the central component which controls the main application life cycle, it inhales the logic registering plugins and managing state. Plugins implement providers which deliver different kinds of data which is required to get the holistic overview of cloud native environmental sustainability. Server The Carbonaut Server hosts an HTTP server which serves collected metrics and serves an access point to configure the deployment at runtime. Detailed information can be found in the api documentation. As of now the server exposes metrics in json format. These metrics could be mapped to prometheus metric types down the road for better integration in the cloud native ecosystem.\nConnector At a higher level, Carbonaut integrates data over providers, and exposes collected data over a server (see Server API docs). Between these two components is the Connector component which contains the main lifecycle of the system.\nInternal Runtime The connector, parses the configuration, starts and stopps plugins, updates the local state which contains the topology of the IT infrastructure and collects data from all connected providers which the API server exposes in different formats. A simplified version of the runtime is visualized below.\nsequenceDiagram autonumber actor A as Alice the Platform Engineer actor J as John the DevOps Engineer participant CMain as Carbonaut CMD participant CServer as Carbonaut Server participant CConn as Carbonaut Connector participant EInfra as Infrastructure Data Sources participant EEnv as Environment Data Sources A-\u003e\u003eCMain: Start Carbonaut activate CMain CMain-\u003e\u003eCConn: Run (main lifecycle) activate CConn CMain-\u003e\u003eCServer: Start Listening activate CServer A--\u003e\u003eCServer: Update Configuration file Note over CConn,EInfra: Carbonaut syncronizes the static resource state of the infrastructure and maintains a mirrored state note right of CConn: Look up configuration file note right of CConn: Update State with Accounts par [Mirror Static Resource \u0026 Environment Data] loop activate CConn note right of CConn: Parse configured 'Accounts' (new, old and remaining) CConn-\u003e\u003eEInfra: Discover 'Projects' (new, old and remaining) note right of CConn: Update State with Projects loop CConn-\u003e\u003eEInfra: Discover 'Resources' by 'Project' (new, old and remaining) note right of CConn: Update State with Resources end deactivate CConn end and [Serve Static \u0026 Dynamic Data] J-\u003e\u003eCServer: I would like to get Carbonaut's metrics activate J activate CServer note right of CServer: Serve from Cache if set CServer-\u003e\u003eCConn: Collect Static and Dynamic Data activate CConn loop Over all Accounts loop Over all Projects loop Over all Resources CConn-\u003e\u003eEInfra: Collect Dynamic Data of the resource (dynres) activate EInfra EInfra--\u003e\u003eCConn: Energy Usage and CPU Frequency data deactivate EInfra CConn-\u003e\u003eEEnv: Collect Dynamic Data (dynenv) activate EEnv EEnv--\u003e\u003eCConn: Energy Mix data deactivate EEnv end end end note right of CConn: Collected dynamic data for each resource note right of CConn: Use static data from state CConn--\u003e\u003eCServer: Return Dynamic and Static Data deactivate CConn CServer--\u003e\u003eJ: Visualize state data deactivate J note right of CServer: Update Cache deactivate CServer end deactivate CConn deactivate CServer CMain--\u003e\u003eA: Carbonaut Stopped deactivate CMainCarbonaut Internal State Carbonaut maintains an internal state which includes data which does not change until a resource was destroyed. Information about how much CPU cores or which Chip Architecture is considered static resource information. Information about the geolocation which indicate where the resource is hosted is considered static environment information. The data schema is defined here.\nProvider \u0026 Plugins Carbonaut collects data of your infrastructure over data providers. Providers are interfaces which are implemented as plugins (see Plugin section in the sidebar). There are three different kinds of providers:\nDynamic Environment Provider collects data about the Energy Mix (may be extended). Dynamic Resource Provider collects data about Energy Usage, CPU Frequency etc. (may be extended). Static Resource Provider collects data about CPU, Memory, IP etc. and also data about the geolocation and region of the IT resource. classDiagram direction LR ResourceData \u003c|-- EnergyMixData : energymix data depends on location \\n data which is part of resource data ResourceData \u003c|-- UtilizationData : utilization data depends \\n on resource data class EnergyMixData{ +SolarPercentage +CoalPercentage +... } class UtilizationData{ +CPUFrequency +EnergyUsage +... } class ResourceData{ +CPUCores +IP +Country +... }\nThese providers depend on each other. To collect energy usage of a system you first need to be aware of the system’s topology. In the cloud environment we have heterogenous systems which changes dynamically. Therefore Resources are captured in projects (like K8s namespace’s) and accounts (like K8s cluster’s). The static resource provider just references the account and further discovery of projects and resources are done at runtime.\nProviders expose interfaces which are defined in the schema reference document. The dynenv provider integrates data about the energy mix. The dynres provider integrates data umong other things about energy usage. The staticres provider integrates data umong other things about Operating System, Memory, Region."},"title":"Carbonaut Components"},"/docs/contributing/":{"data":{"":"","#":"The Carbonaut project is a POC project and therefore no community structures are in place. If you find this project interesting enough to contribute, please open up an issue on the repository or directly a PR to discuss your idea. Any contributions are very welcome!\nDevelopment Workflow Fork the repository and work on your fork. It’s recommended to create a feature branch on your fork and open pull requests from feature branches to Carbonaut’s main branch. If you have questions about forks, branches etc. take a look at GitHub’s documentation. If you forked the repository, install all dependencies, Go, pre-commit and then run make install to install other go nbased tools (see Makefile). If you intend to make changes to the manual testing scenario, refer to this guide. After that you can run make verify to check if everything is setup for local development. Ways of communication GitHub issues and pull requests on the Carbonaut repository (no forks!) Additional Comments by area of contribution Improve internal code: improvments are welcome! There are several TODO: XYZ annotations in the code that highlight some areas of improvements. Increasing test coverage and quality: improvements are welcome! The test coverage is not great. Test coverage is uploaded as artifact with each push to the main branch (see actions). You can also run test coverage of the Go code by executing make test-coverage. Adding Provider Plugins: make sure to test it both mocked and as E2E test. Proposing changing data schema or API: sure, make your case. The datamodels are minimal and not complete, changes are welcome. Improvements to this document are welcome!"},"title":"Contributing"},"/docs/guides/":{"data":{"":" How to Run Carbonaut How to Setup Dev Environment How to Develop Internals How to Develop Plugins How to Test E2E "},"title":"Guides"},"/docs/guides/how-to-build/":{"data":{"":"","#":"The project pushes binaries to the GitHub release and Docker containers to Docker hub. If you prefer to build binaries manually, you can follow these instructions. In general the entire build process pushing to GitHub and Docker Hub is public and part of the Carbonaut repository.\nPrerequisits install project dependencies Setup your dev environment. Follow this guide.\nBuild Go Binaries ℹ️ documentation not yet added Build Container Images ℹ️ documentation not yet added "},"title":"Build Carbonaut Manually"},"/docs/guides/how-to-develop-internals/":{"data":{"":"","#":"This guide gives information how to start develop internals of Carbonaut. Carbonauts source code is developed in Go and located in the pkg/ directory of the project. After this guide you are able to make changes, verify if made changes work and how to push these changes and get towards merging it to the main Carbonaut project.\nSetup Read the contributors guide here and fork the carbonaut repository. Setup your dev environment. Follow this guide. Test building the project locally make build Run Carbonaut in test-run mode ./main --test-run. Carbonaut will load a test config and shut down after a couple of seconds automatically. Make changes to the codebase Open up any edit and make changes to the code base. You can run unit tests and linting with make verify. During that process a coverage.html will be generated which can be used to explore test coverage.\nVerify changes made Run make verify. INFO: Some steps run commands like go mod tidy which may change go.mod (depending on your edits) if go.mod was changed during make verify, the check will fail but its safe to rerun it. Optionally you can run e2e checks see this guide "},"title":"Develop Internals"},"/docs/guides/how-to-develop-plugins/":{"data":{"":"","#":" Setup Setup your dev environment. Follow this guide. Read up the concepts documentation about provider and plugins. Identify which provider interface you need to implement Choose the provider which is used to implement the data you like to integrate. dynres implements energy usage, cpu frequency etc. staticres implements cloud provider, hypervisors etc. that manage your infrastructure resources. dynenv implements energy grid APIs Setup your starting point (one of these) dynres: Copy the folder pkg/plugin/dynresplugins/mockenergy and rename it to your plugins name staticres: Copy the folder pkg/plugin/staticresplugins/mockcloudplugin and rename it to your plugins name dynenv: Copy the folder pkg/plugin/dynenvplugins/mockenergymix and rename it to your plugins name Implement your Plugin Implement the provider interface. Add unit, integration and optional end to end testing. Make sure to add the provider reference to the plugin file: For dynres add it to pkg/plugin/dynresplugins/dynresplugins.go For staticres add it to pkg/plugin/staticresplugins/staticresplugins.go For dynenv add it to pkg/plugin/dynenvplugins/dynenvplugins.go If applicable add caching. type p struct { // ... cache *cache.Cache } func New(cfg *Config) (p, error) { // Create a cache with an expiration time of 60 seconds, and which // purges expired items every 5 minutes c := cache.New(60*time.Second, 5*time.Minute) // ... } func reqData(id string) (*Data, error) { // ... if cachedData, found := p.cache.Get(id); found { return cachedData, nil } // ... if err := p.cache.Add(id, data, cache.DefaultExpiration); err != nil { return nil, errors.New(\"unable to add data to internal cache\") } // ... } Push changes Push changes and open a PR to propose merging changes to Carbonaut. See contribution guide."},"title":"Develop Plugins"},"/docs/guides/how-to-run/":{"data":{"":"","#":"Carbonaut can be run as binary or container. The latest releases can be found here.\nStep 1 This is the first step.\nStep 2 This is the second step.\nStep 3 This is the third step."},"title":"How to Run Carbonaut"},"/docs/guides/how-to-setup-dev-environment/":{"data":{"":"","#":"This guide gives information how to start setup your development environment so you are ready to customize the current Carbonaut version.\nThere are two options which you can use. Either you use a vscode dev container which uses Docker in the background as virtualized dev environment. Or you use your regular machine for development. If you are on Windows you need to work with WSL (Linux Subsystem for Windows) and note that there may be some issues since Carbonaut was developed on macOS and not tested on other platforms. If any step is not working, please open a PR to improve this document.\n⚠️ Make sure to work on a fork and not the cloned carbonaut repository! See the contributor guide for more information. GO \u0026 NPM Install Go and NPM. Go is used to compile the project and install additional tooling like golangci-lint. NPM is used to install additional tooling like pre-commit and prettier for formatting. All installs are listed in the Makefile under installs\nCurrent Go version used on macOS go version go1.22.2 darwin/arm64 Current NPM version used on macOS 10.8.0 MAKE Install Install dependencies with make install.\nOptional: Use VSCode Dev Containers ℹ️ Dev Containers are not yet implemented. "},"title":"Setup Development Environment"},"/docs/guides/how-to-test-e2e/":{"data":{"":"","#":" Setup your dev environment. Follow this guide. Setup your Dev Environment This is the first step.\nStep 2 This is the second step.\nStep 3 This is the third step."},"title":"Test End To End (E2E)"},"/docs/plugins/":{"data":{"":" Dynamic Environment Plugins Static Resource Plugins Dynamic Resource Plugins "},"title":"Plugins"},"/docs/plugins/dyn-environment/":{"data":{"":" Energy Map "},"title":"Dynamic Environment"},"/docs/plugins/dyn-environment/energy-map/":{"data":{"":" ℹ️ documentation not yet added Electricity Map: (you can get a free tier account here)"},"title":"Energy Map Plugin"},"/docs/plugins/dyn-resource/":{"data":{"":" Scaphandre "},"title":"Dynamic Resource"},"/docs/plugins/dyn-resource/scaphandre/":{"data":{"":" ℹ️ documentation not yet added Scaphandre"},"title":"Scaphandre Plugin"},"/docs/plugins/static-resource/":{"data":{"":" Equinix "},"title":"Static Resource"},"/docs/plugins/static-resource/equinix/":{"data":{"":" ℹ️ documentation not yet added Equinix"},"title":"Equinix Plugin"},"/docs/reference/":{"data":{"":" Data Schema Server API "},"title":"Reference"},"/docs/reference/schema/":{"data":{"dynenv#dynenv":"import \"carbonaut.dev/pkg/provider/types/dynenv\" ","dynres#dynres":"import \"carbonaut.dev/pkg/provider/types/dynres\" ","environment#environment":"import \"carbonaut.dev/pkg/provider/environment\" ","index#Index":" type Config type Data type EnvConfig type Res type ResConfig ","index-1#Index":" type DynamicEnvData ","index-2#Index":" type Kind ","index-3#Index":" type AccountData type AccountName type CPU type DRIVE type DynamicData type DynamicResData type GPU type Location type NIC type OS type ProjectData type ProjectName type ResourceData type ResourceName type StaticData type StaticResData ","index-4#Index":" Variables type AccountID type AccountT type ProjectID type ProjectT type Projects type ResourceID type ResourceT type Resources type T ","index-5#Index":" type Config type Provider ","index-6#Index":" type Config type Provider ","index-7#Index":" type Config type Provider ","plugin#plugin":"import \"carbonaut.dev/pkg/provider/plugin\" ","provider#provider":" providerimport \"carbonaut.dev/pkg/provider\" ","resource#resource":"import \"carbonaut.dev/pkg/provider/resource\" ","staticres#staticres":"import \"carbonaut.dev/pkg/provider/types/staticres\" ","topology#topology":"import \"carbonaut.dev/pkg/provider/topology\" ","type-accountdata#type AccountData":"type AccountData map[ProjectName]ProjectData ","type-accountid#type AccountID":"type AccountID int32 ","type-accountname#type AccountName":"type AccountName string ","type-accountt#type AccountT":"type AccountT struct { Name *resource.AccountName `json:\"name\"` Projects Projects `json:\"projects\"` CreatedAt time.Time `json:\"created_at\"` ProjectIDCounter *int32 `json:\"-\"` Config *staticres.Config `json:\"-\"` } ","type-config#type Config":"type Config struct { Resources ResConfig `json:\"resources\" yaml:\"resources\"` Environment *EnvConfig `json:\"environment\" yaml:\"environment\"` } ","type-config-1#type Config":"type Config struct { Plugin *plugin.Kind `json:\"plugin\" yaml:\"plugin\"` AccessKeyEnv *string `json:\"access_key_env\" yaml:\"access_key_env\"` } ","type-config-2#type Config":"type Config struct { Plugin plugin.Kind `json:\"plugin\" yaml:\"plugin\"` // Endpoint that is accessed to collec the data. // The IPv4 address will be collected from the static data thats looked up. Endpoint string `json:\"endpoint\" yaml:\"endpoint\"` // Client certificate file Cert string `json:\"cert\" yaml:\"cert\"` // Client certificate's key file Key string `json:\"key\" yaml:\"key\"` // Accept any certificate during TLS handshake. Insecure, use only for testing AcceptInvalidCert bool `json:\"accept_invalid_cert\" yaml:\"accept_invalid_cert\"` } ","type-config-3#type Config":"type Config struct { Plugin *plugin.Kind `json:\"plugin\" yaml:\"plugin\"` AccessKeyEnv *string `json:\"access_key_env\" yaml:\"access_key_env\"` } ","type-cpu#type CPU":"type CPU struct { Count int `json:\"count\" yaml:\"count\" default:\"1\"` Type string `json:\"type\" yaml:\"type\" default:\"Intel Xeon E-2278G 8-Core Processor @ 3.40GHz\"` Cores string `json:\"cores\" yaml:\"cores\" default:\"8\"` Threads string `json:\"threads\" yaml:\"threads\" default:\"16\"` Speed string `json:\"speed\" yaml:\"speed\" default:\"3.40GHz\"` Arch string `json:\"arch\" yaml:\"arch\" default:\"x86\"` Model string `json:\"model\" yaml:\"model\" default:\"E-2278G\"` Manufacturer string `json:\"manufacturer\" yaml:\"manufacturer\" default:\"Intel\"` Name string `json:\"name\" yaml:\"name\" default:\"Intel Xeon E-2278G Processor\"` } ","type-data#type Data":"type Data map[resource.AccountName]resource.AccountData ","type-drive#type DRIVE":"type DRIVE struct { Count int `json:\"count\" yaml:\"count\" default:\"2\"` Type string `json:\"type\" yaml:\"type\" default:\"SSD\"` Size string `json:\"size\" yaml:\"type\" default:\"480GB\"` } ","type-dynamicdata#type DynamicData":"type DynamicData struct { ResData *DynamicResData `json:\"res_data\" yaml:\"res_data\"` EnvData *environment.DynamicEnvData `json:\"env_data\" yaml:\"env_data\"` } ","type-dynamicenvdata#type DynamicEnvData":"type DynamicEnvData struct { SolarPercentage float64 `json:\"solar_percentage\" yaml:\"solar_percentage\"` WindPercentage float64 `json:\"wind_percentage\" yaml:\"wind_percentage\"` HydroPercentage float64 `json:\"hydro_percentage\" yaml:\"hydro_percentage\"` NuclearPercentage float64 `json:\"nuclear_percentage\" yaml:\"nuclear_percentage\"` GeothermalPercentage float64 `json:\"geothermal_percentage\" yaml:\"geothermal_percentage\"` GasPercentage float64 `json:\"gas_percentage\" yaml:\"gas_percentage\"` OilPercentage float64 `json:\"oil_percentage\" yaml:\"oil_percentage\"` BiomassPercentage float64 `json:\"biomass_percentage\" yaml:\"biomass_percentage\"` CoalPercentage float64 `json:\"coal_percentage\" yaml:\"coal_percentage\"` OtherSourcesPercentage float64 `json:\"other_sources_percentage\" yaml:\"other_sources_percentage\"` FossilFuelsPercentage float64 `json:\"fossil_fuels_percentage\" yaml:\"fossil_fuels_percentage\"` RenewablePercentage float64 `json:\"renewable_percentage\" yaml:\"renewable_percentage\"` } ","type-dynamicresdata#type DynamicResData":"energy and utilization data\ntype DynamicResData struct { CPUFrequency float64 `json:\"cpu_frequency\" yaml:\"cpu_frequency\"` EnergyHostMicrojoules int `json:\"energy_host_mirojoules\" yaml:\"energy_host_mirojoules\"` CPULoadPercentage float64 `json:\"cpu_load_percentage\" yaml:\"cpu_load_percentage\"` } ","type-envconfig#type EnvConfig":"type EnvConfig struct { DynamicEnvConfig *dynenv.Config `json:\"dynamic_environment\" yaml:\"dynamic_environment\"` } ","type-gpu#type GPU":"type GPU struct { Count int `json:\"count\" yaml:\"count\" default:\"1\"` Type string `json:\"type\" yaml:\"type\" default:\"Intel HD Graphics P630\"` } ","type-kind#type Kind":"type Kind string ","type-location#type Location":"type Location struct { City string `json:\"city\" yaml:\"city\" default:\"Frankfurt\"` Country string `json:\"country\" yaml:\"country\" default:\"DE\"` Address string `json:\"address\" yaml:\"address\" default:\"Kruppstrasse 121-127\"` ZipCode string `json:\"zip_code\" yaml:\"zip_code\" default:\"60388\"` Code string `json:\"code\" yaml:\"code\" default:\"fr\"` } ","type-nic#type NIC":"type NIC struct { Count int `json:\"count\" yaml:\"count\" default:\"1\"` Type string `json:\"type\" yaml:\"type\" default:\"10Gbps\"` } ","type-os#type OS":"type OS struct { Version string `json:\"version\" yaml:\"version\" default:\"12\"` Distro string `json:\"distro\" yaml:\"distro\" default:\"debian\"` Name string `json:\"name\" yaml:\"name\" default:\"Debian 12\"` } ","type-projectdata#type ProjectData":"type ProjectData map[ResourceName]*ResourceData ","type-projectid#type ProjectID":"type ProjectID int32 ","type-projectname#type ProjectName":"type ProjectName string ","type-projects#type Projects":"type Projects map[ProjectID]*ProjectT ","type-projectt#type ProjectT":"type ProjectT struct { Name *resource.ProjectName `json:\"name\"` Resources Resources `json:\"resources\"` CreatedAt time.Time `json:\"created_at\"` ResourceIDCounter *int32 `json:\"-\"` } ","type-provider#type Provider":"type Provider interface { GetName() *plugin.Kind GetDynamicEnvironmentData(*resource.Location) (*environment.DynamicEnvData, error) } ","type-provider-1#type Provider":"type Provider interface { GetName() *plugin.Kind GetDynamicResourceData(*resource.StaticResData) (*resource.DynamicResData, error) } ","type-provider-2#type Provider":"type Provider interface { GetName() *plugin.Kind GetStaticResourceData(*resource.ProjectName, *resource.ResourceName) (*resource.StaticResData, error) DiscoverStaticResourceIdentifiers(*resource.ProjectName) ([]*resource.ResourceName, error) DiscoverProjectIdentifiers() ([]*resource.ProjectName, error) } Generated by gomarkdoc","type-res#type Res":"type Res struct { StaticResConfig *staticres.Config `json:\"static_resource\" yaml:\"static_resource\"` DynamicResConfig *dynres.Config `json:\"dynamic_resource\" yaml:\"dynamic_resource\"` } ","type-resconfig#type ResConfig":"type ResConfig map[resource.AccountName]Res ","type-resourcedata#type ResourceData":"type ResourceData struct { DynamicData *DynamicData `json:\"dynamic_data\" yaml:\"dynamic_data\"` StaticData *StaticResData `json:\"static_data\" yaml:\"static_data\"` } ","type-resourceid#type ResourceID":"type ResourceID int32 ","type-resourcename#type ResourceName":"type ResourceName string ","type-resources#type Resources":"type Resources map[ResourceID]*ResourceT ","type-resourcet#type ResourceT":"internal state\ntype ResourceT struct { Name *resource.ResourceName `json:\"name\"` StaticData *resource.StaticResData `json:\"static_data\"` CreatedAt time.Time `json:\"created_at\"` Plugin *plugin.Kind `json:\"plugin\"` } ","type-staticdata#type StaticData":"type StaticData struct { ResData *StaticResData `json:\"res_data\" yaml:\"res_data\"` } ","type-staticresdata#type StaticResData":"Data represents computer hardware data.\ntype StaticResData struct { ID string `json:\"id\" yaml:\"id\" default:\"0131acc3-82d8-488b-a8e2-c4a00e897145\"` User string `json:\"user\" yaml:\"user\" default:\"root\"` OS *OS `json:\"os\" yaml:\"os\"` IPv4 string `json:\"ipv4\" yaml:\"ipv4\" default:\"145.40.93.80\"` CPUs []*CPU `json:\"cpus\" yaml:\"cpus\"` GPUs []*GPU `json:\"gpus\" yaml:\"gpus\"` NICs []*NIC `json:\"nics\" yaml:\"nics\"` Drives []*DRIVE `json:\"drives\" yaml:\"drives\"` MemoryGB string `json:\"memory_gb\" yaml:\"memory_gb\" default:\"32GB\"` Location *Location `json:\"location\" yaml:\"location\"` } ","type-t#type T":"type T struct { Accounts map[AccountID]*AccountT `json:\"accounts\" yaml:\"accounts\"` AccountsIDCounter *int32 `json:\"-\"` } ","variables#Variables":"\nvar ( AccountNotFoundID AccountID = -1 ProjectNotFoundID ProjectID = -1 ResourceNotFoundID ResourceID = -1 ) "},"title":"Data Schema"},"/docs/reference/server-api/":{"data":{"":"","carbonaut-server-api#\u003cstrong\u003eCarbonaut Server API\u003c/strong\u003e":"Carbonaut Server API The Carbonaut Server is a lightweight HTTP server designed to provide metrics and static data management using a caching mechanism to optimize data delivery. This server is built using Go and utilizes a custom connector for data retrieval and a cache for data storage.\nConfiguration Struct: Config Port (int): The network port on which the server listens. Default is 8088. The port can be specified in the config.yaml. HTTP Endpoints / Method: GET Description: Returns a message indicating that the Carbonaut Server is running and displays the metrics collection endpoint. /static-data Method: GET Description: Provides static data retrieved via the connector. If available, data is served from the cache; otherwise, it is retrieved from the state and cached. /metrics-json Method: GET Description: Returns collected data metrics. If available, data is served from the cache; otherwise, it is freshly collected, serialized to JSON, and cached. /stop Method: GET Description: Stops the server. It sends a signal through the ExitChan to shut down the server. Caching Strategy The server employs a simple caching mechanism with a fixed expiration time for entries. It purges expired items every 5 minutes and caches both metrics data and static data for quick access."},"title":"Server API"}}